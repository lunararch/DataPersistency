{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:30:38.652887Z",
     "end_time": "2023-08-31T14:31:43.612851Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "import ConnectionConfig as cc\n",
    "cc.setupEnvironment()\n",
    "spark = cc.startLocalCluster(\"SQLExcersice\")\n",
    "spark.getActiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Go to https://spark.apache.org/docs/latest/sql-getting-started.html and https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html#Quickstart:-DataFrame to get some insights in coding Spark SQL. Always select 'Python' as the language.\n",
    "\n",
    "Use the Spark SQL Reference documentation to complete this excercise\n",
    "- To write dataframe operations: Python SparkSQL API: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html\n",
    "- To write pure SQL statements: Spark SQL API: https://spark.apache.org/docs/2.3.0/api/sql/index.html and https://spark.apache.org/docs/latest/sql-ref.html\n",
    "Helpfull site with examples: https://sparkbyexamples.com/pyspark/\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load employees.csv as a Spark Dataframe\n",
    "Tip: https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html#Getting-Data-In/Out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:31:43.617865Z",
     "end_time": "2023-08-31T14:31:50.554853Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Display the schema of the DataFrame\n",
    "Tip: https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html#Getting-Data-In/Out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:31:50.556853Z",
     "end_time": "2023-08-31T14:31:50.568853Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a temperary view of the dataset with name tbl_employees\n",
    "https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html#Getting-Data-In/Out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:31:50.574854Z",
     "end_time": "2023-08-31T14:31:50.756850Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Calculate the total number of employees in two ways:\n",
    "-   Via dataframe operations: Tip: https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html#Grouping-Data\n",
    "-   With a sql statement op tbl_employees: use spark.sql()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:31:50.673855Z",
     "end_time": "2023-08-31T14:31:51.707855Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:31:51.711855Z",
     "end_time": "2023-08-31T14:31:52.294868Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find the average salary of all employees in two ways:\n",
    "-   Via the dataframe operation 'select'\n",
    "-   With a sql statement ont tbl_employees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:31:52.294868Z",
     "end_time": "2023-08-31T14:31:52.830855Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:31:52.835858Z",
     "end_time": "2023-08-31T14:31:53.295859Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get the explain plan of the sql statement\n",
    "1. use the method explain(mode=\"extended\") on the spark.sql statement and look  at the different plans Spark created to excecute the query.\n",
    "2. Read the physical plan from bottom to top and try to match the plan with the query you wrote. (Exchange means that the data is being shuffled between the executors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:31:53.260874Z",
     "end_time": "2023-08-31T14:31:53.438857Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find the highest salary in each department in two ways:\n",
    "-  Via the dataframe operation 'groupBy'\n",
    "-  With a sql statement ont tbl_employees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:31:53.402863Z",
     "end_time": "2023-08-31T14:31:55.008855Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate the total salary expenditure for each year"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:31:55.005855Z",
     "end_time": "2023-08-31T14:31:56.008862Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate the number of employees per postal code\n",
    "Postal codes are available in the parquet file empPostalCodes\n",
    "Create a view for the parquet file and join the two datasets in the sql-query\n",
    "Also check the explain plan of the query (Project means that the data is reduced to the columns needed for the query, BroadcastHashJoin means that the smaller dataset is broadcasted to all executors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T14:31:56.014853Z",
     "end_time": "2023-08-31T14:31:57.777856Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
